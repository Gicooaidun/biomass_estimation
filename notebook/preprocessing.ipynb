{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "### Input Folder structure:\n",
    "\n",
    "```\n",
    "notebook\n",
    "├── boreal_agb_density_ICESat2_tiles_shp\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.dbf\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.prj\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.sbn\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.sbx\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.shp\n",
    "|       - Boreal_AGB_Density_ICESat2_tiles.shx\n",
    "├── data\n",
    "|   - download_icesat.sh\n",
    "├── S2_tiles_Siberia_polybox\n",
    "|   - S2_tiles_Siberia_above_GEDI.geojson\n",
    "|   - S2_tiles_Siberia_all.geojson\n",
    "|   - S2_tiles_Siberia_within_GEDI.geojson\n",
    "- preprocessing.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import rasterio as rs\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the corresponding IceSat-2 tiles for every Sentinel-2 tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Sentinel 2 shapefile\n",
    "s2_df = gpd.read_file('S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False) \n",
    "# print(s2_df.head())\n",
    "#reading in ICESat2 shapefile\n",
    "icesat_df = gpd.read_file('boreal_agb_density_ICESat2_tiles_shp/Boreal_AGB_Density_ICESat2_tiles.shp', driver='ESRI Shapefile', index = False)\n",
    "# print(icesat_df.head())\n",
    "        \n",
    "overlapping_tiles = pd.DataFrame()\n",
    "#iterating over each Sentinel 2 tile and finding the ICESat2 tiles that overlap with it\n",
    "for _, s2_tile in s2_df.iterrows():\n",
    "    s2_geometry = s2_tile.geometry\n",
    "    overlapping_icesat_tiles = icesat_df[icesat_df.geometry.intersects(s2_geometry)].copy()\n",
    "\n",
    "    # adding the name of the S2 tile to the ICESat2 tiles that overlap with it\n",
    "    if not overlapping_icesat_tiles.empty:\n",
    "        overlapping_icesat_tiles.loc[:, 'S2 Tile Name'] = s2_tile.Name\n",
    "        # overlapping_icesat_tiles.loc[:, 'S2 Tile Geometry'] = s2_geometry\n",
    "    \n",
    "    overlapping_tiles = pd.concat([overlapping_tiles, overlapping_icesat_tiles])\n",
    "\n",
    "# overlapping_tiles_df = gpd.GeoDataFrame(overlapping_tiles, columns=['S2 Tile Name', 'Overlapping ICESat Tiles'])\n",
    "overlapping_tiles.to_csv('overlapping_tiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing to download, create a 'links.txt' file which contains the download links of the relevant IceSat-2 granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'overlapping_tiles.csv'\n",
    "\n",
    "# Get the column index of \"GeoTiff\"\n",
    "geo_tiff_column_index = overlapping_tiles.columns.get_loc(\"GeoTIFF\")\n",
    "\n",
    "filenames = []\n",
    "\n",
    "with open(csv_file, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    for row in csv_reader:\n",
    "        if row[geo_tiff_column_index] not in filenames:\n",
    "            filenames.append(row[geo_tiff_column_index])\n",
    "\n",
    "# print(filenames)\n",
    "\n",
    "with open('links.txt', 'w') as file:\n",
    "    for filename in filenames:\n",
    "        file.write('https://data.ornldaac.earthdata.nasa.gov/protected/above/Boreal_AGB_Density_ICESat2/data/' + filename + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 'download_icesat.sh' \n",
    "The script should be located in the '/data' folder. Replace 'username' and 'password' with your ***correct*** earthdata credentials\n",
    "\n",
    "Open a terminal in the '/data' folder and run:\n",
    "\n",
    "\\>\\> chmod 777 download_icesat.sh\n",
    "\n",
    "\\>\\> ./download_icesat.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Mosaic the tiles together\n",
    "\n",
    "This will create a \"/merged_mosaic\" folder where for every Sentinel-2 tile we save the overlapping IceSat-2 tiles mosaiced together as [S2-tilename]_mosaic.tif These mosaiced tiles are still in the IceSat-2 crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tile 50TPS...\n",
      "Processing tile 50TPT...\n",
      "Processing tile 50TQS...\n",
      "Processing tile 50TQT...\n",
      "Processing tile 50UQA...\n",
      "Processing tile 50UQB...\n",
      "Processing tile 51TVL...\n",
      "Processing tile 51TVM...\n",
      "Processing tile 51TVN...\n",
      "Processing tile 51TWM...\n",
      "Processing tile 51TWN...\n",
      "Processing tile 51UUP...\n",
      "Processing tile 51UUQ...\n",
      "Processing tile 51UUT...\n",
      "Processing tile 51UVP...\n",
      "Processing tile 51UVQ...\n",
      "Processing tile 51UVR...\n",
      "Processing tile 51UVS...\n",
      "Processing tile 51UVT...\n",
      "Processing tile 51UWP...\n",
      "Processing tile 51UWQ...\n",
      "Processing tile 51UWR...\n",
      "Processing tile 51UWS...\n",
      "Processing tile 51UWT...\n",
      "Processing tile 51UXQ...\n",
      "Processing tile 51UXR...\n",
      "Processing tile 51UXS...\n",
      "Processing tile 51UXT...\n",
      "Processing tile 51UYS...\n",
      "Processing tile 51UYT...\n",
      "Processing tile 52UCA...\n",
      "Processing tile 52UDA...\n",
      "Processing tile 52UDB...\n",
      "Processing tile 52UDC...\n",
      "Processing tile 52UEA...\n",
      "Processing tile 52UEB...\n",
      "Processing tile 52UEC...\n",
      "Processing tile 52UEV...\n",
      "Processing tile 52UFA...\n",
      "Processing tile 52UFB...\n",
      "Processing tile 52UFC...\n",
      "Processing tile 52UFU...\n",
      "Processing tile 52UFV...\n",
      "Processing tile 52UGB...\n",
      "Processing tile 52UGU...\n",
      "Processing tile 53TMK...\n",
      "Processing tile 53TML...\n",
      "Processing tile 53TMM...\n",
      "Processing tile 53TNK...\n",
      "Processing tile 53TNL...\n",
      "Processing tile 53TNM...\n",
      "Processing tile 53TNN...\n",
      "Processing tile 53TPL...\n",
      "Processing tile 53TPM...\n",
      "Processing tile 53TPN...\n",
      "Processing tile 53TQM...\n",
      "Processing tile 53TQN...\n",
      "Processing tile 53ULQ...\n",
      "Processing tile 53ULR...\n",
      "Processing tile 53ULT...\n",
      "Processing tile 53UMP...\n",
      "Processing tile 53UMQ...\n",
      "Processing tile 53UMR...\n",
      "Processing tile 53UMS...\n",
      "Processing tile 53UMT...\n",
      "Processing tile 53UNP...\n",
      "Processing tile 53UNQ...\n",
      "Processing tile 53UNR...\n",
      "Processing tile 53UNS...\n",
      "Processing tile 53UNT...\n",
      "Processing tile 53UPP...\n",
      "Processing tile 53UPQ...\n",
      "Processing tile 53UPR...\n",
      "Processing tile 53UPS...\n",
      "Processing tile 53UPT...\n",
      "Processing tile 54UUA...\n",
      "Processing tile 54UUB...\n",
      "Processing tile 54UUC...\n",
      "Processing tile 54UUU...\n",
      "Processing tile 54UUV...\n",
      "Processing tile 54UVA...\n",
      "Processing tile 54UVB...\n",
      "Processing tile 54UVC...\n",
      "Processing tile 54UVU...\n",
      "Processing tile 54UVV...\n",
      "Processing tile 52VDR...\n",
      "Processing tile 52UDD...\n",
      "Processing tile 52UDE...\n",
      "Processing tile 52UDF...\n",
      "Processing tile 52UDG...\n",
      "Processing tile 52UED...\n",
      "Processing tile 52UEE...\n",
      "Processing tile 52UEF...\n",
      "Processing tile 52UEG...\n",
      "Processing tile 52VDH...\n",
      "Processing tile 52VDJ...\n",
      "Processing tile 52VDK...\n",
      "Processing tile 52VDL...\n",
      "Processing tile 52VDM...\n",
      "Processing tile 52VDN...\n",
      "Processing tile 52VDP...\n",
      "Processing tile 52VDQ...\n",
      "Processing tile 52VEH...\n",
      "Processing tile 52VEJ...\n",
      "Processing tile 52VEK...\n",
      "Processing tile 52VEL...\n",
      "Processing tile 52VEM...\n",
      "Processing tile 52VEN...\n",
      "Processing tile 52VEP...\n",
      "Processing tile 52VEQ...\n",
      "Processing tile 52VER...\n",
      "Processing tile 52WDS...\n",
      "Processing tile 52WDT...\n",
      "Processing tile 52WDU...\n",
      "Processing tile 52WDV...\n",
      "Processing tile 52WES...\n",
      "Processing tile 52WET...\n",
      "Processing tile 52WEU...\n",
      "Processing tile 52WEV...\n",
      "Processing tile 52UFD...\n",
      "Processing tile 52UFE...\n",
      "Processing tile 52UFF...\n",
      "Processing tile 52UFG...\n",
      "Processing tile 52VFH...\n",
      "Processing tile 52VFJ...\n",
      "Processing tile 52VFK...\n",
      "Processing tile 52VFL...\n",
      "Processing tile 52VFM...\n",
      "Processing tile 52VFN...\n",
      "Processing tile 52VFP...\n",
      "Processing tile 52VFQ...\n",
      "Processing tile 52VFR...\n",
      "Processing tile 52WFS...\n",
      "Processing tile 52WFT...\n",
      "Processing tile 52WFU...\n",
      "Processing tile 52WFV...\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "\n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "    icesat_tiles = []\n",
    "    for index, row in df[df['S2 Tile Name']==tile].iterrows():\n",
    "        icesat_tiles.append(row['GeoTIFF'])\n",
    "    \n",
    "    to_merge = []\n",
    "    # Construct the path to the corresponding tif file\n",
    "    for icesat_tile in icesat_tiles:\n",
    "        temp_tiff = rs.open(f'data/{icesat_tile}')\n",
    "        to_merge.append(temp_tiff)\n",
    "    \n",
    "    assert len(to_merge)!=0, \"No corresponding ICESat-2 tiles found\"\n",
    "    # Check if the CRS of all the to_merge are the same\n",
    "    crs_check = all(to_merge[0].crs == t.crs for t in to_merge)\n",
    "    if not crs_check:\n",
    "        raise ValueError(\"CRS of the to_merge tiles are not the same\")\n",
    "  \n",
    "    # Merge the tiles\n",
    "    mosaic, mosaic_trans = merge(to_merge)\n",
    "    mosaic_crs = to_merge[0].crs\n",
    "\n",
    "    height, width = mosaic.shape[1], mosaic.shape[2]\n",
    "    output_meta = to_merge[0].meta.copy()\n",
    "    output_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": height,\n",
    "                        \"width\": width,\n",
    "                        \"transform\": mosaic_trans,\n",
    "                        \"count\": mosaic.shape[0]})\n",
    "    output_path = f'merged_mosaic/{tile}_mosaic.tif'\n",
    "\n",
    "    # Specify the path to the merged_mosaic folder\n",
    "    merged_mosaic_folder = 'merged_mosaic'\n",
    "\n",
    "    # Check if the merged_mosaic folder exists\n",
    "    if not os.path.exists(merged_mosaic_folder):\n",
    "        # Create the merged_mosaic folder\n",
    "        os.makedirs(merged_mosaic_folder)\n",
    "    \n",
    "    with rs.open(output_path, \"w\", **output_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "\n",
    "    # Close the tiles' files\n",
    "    for src in to_merge : src.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reprojecting the mosaics\n",
    "\n",
    "We reproject the mosaics from the IceSat-2 crs to the Sentinel-2 crs and save them to the \"/reprojected_mosaic\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper function to get the CRS of the Sentinel-2 tile from its name\n",
    "# it is used in both reprojecting and cropping the tiles\n",
    "def get_CRS_from_S2_tilename(tname) :\n",
    "    \"\"\"\n",
    "    Get the CRS of the Sentinel-2 tile from its name. The tiles are named as DDCCC (where D is a digit and C a character).\n",
    "    MGRS tiles are in UTM projection, which means the CRS will be EPSG=326xx in the Northern Hemisphere, and 327xx in the\n",
    "    Southern. The first character of the tile name gives you the hemisphere (C to M is South, N to X is North); and the\n",
    "    two digits give you the UTM zone number.\n",
    "\n",
    "    Args:\n",
    "    - tname: str, name of the Sentinel-2 tile\n",
    "\n",
    "    Returns:\n",
    "    - rasterio.crs.CRS, the CRS of the Sentinel-2 tile\n",
    "    \"\"\"\n",
    "\n",
    "    tile_code, hemisphere = tname[:2], tname[2]\n",
    "\n",
    "    if 'C' <= hemisphere <= 'M':\n",
    "        crs = f'EPSG:327{tile_code}'\n",
    "    elif 'N' <= hemisphere <= 'X':\n",
    "        crs = f'EPSG:326{tile_code}'\n",
    "    else:\n",
    "        raise ValueError(f'Invalid hemisphere code: {hemisphere}')\n",
    "    \n",
    "    return rs.crs.CRS.from_string(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the original raster dataset\n",
    "def custom_reproject(src_path, output_path, dst_crs):\n",
    "    # Open the original raster dataset\n",
    "    with rs.open(src_path) as src:\n",
    "        \n",
    "        # Calculate the transformation parameters and the width and height of the output\n",
    "        # in the new CRS\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        \n",
    "        # Copy the metadata from the source dataset\n",
    "        kwargs = src.meta.copy()\n",
    "        # Update the metadata with the new CRS, transformation, and dimensions\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        # Specify the path to the merged_mosaic folder\n",
    "        reprojected_mosaic_folder = 'reprojected_mosaic'\n",
    "\n",
    "        # Check if the merged_mosaic folder exists\n",
    "        if not os.path.exists(reprojected_mosaic_folder):\n",
    "            # Create the merged_mosaic folder\n",
    "            os.makedirs(reprojected_mosaic_folder)\n",
    "\n",
    "        # Open a new raster file for the reprojected data\n",
    "        with rs.open(output_path, 'w', **kwargs) as dst:\n",
    "            \n",
    "            # Reproject each band in the raster dataset\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    # Source raster band\n",
    "                    source=rs.band(src, i),\n",
    "                    # Destination raster band\n",
    "                    destination=rs.band(dst, i),\n",
    "                    # Source transformation and CRS\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    # Destination transformation and CRS\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    # Resampling method\n",
    "                    resampling=Resampling.nearest)\n",
    "\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "    \n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "\n",
    "    dest_crs = get_CRS_from_S2_tilename(tile)\n",
    "\n",
    "    # Read in the (tile)_mosaic.tif file\n",
    "    mosaic_file = f'merged_mosaic/{tile}_mosaic.tif'\n",
    "    custom_reproject(mosaic_file, f'reprojected_mosaic/{tile}_reprojected_mosaic.tif', dest_crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping the reprojected mosaics\n",
    "We crop the reprojected mosaics to the corresponding Sentinel-2 tile and save them to the \"/cropped_mosaic\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'reprojected_mosaic'\n",
    "\n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    # Get the file paths of all the files in the directory\n",
    "    file_path = os.path.join(directory, tile + \"_reprojected_mosaic.tif\")\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "\n",
    "    \n",
    "    #reproject the tiles to the same CRS\n",
    "    dest_crs = get_CRS_from_S2_tilename(tile)\n",
    "    # print(\"entry.crs:  \" + str(entry.crs))\n",
    "    reprojected_entry = entry.to_crs(dest_crs, inplace=False)\n",
    "    # print(reprojected_entry.crs.to_epsg())\n",
    "\n",
    "    # Specify the path to the merged_mosaic folder\n",
    "    cropped_mosaic_folder = 'cropped_mosaic'\n",
    "\n",
    "    # Check if the merged_mosaic folder exists\n",
    "    if not os.path.exists(cropped_mosaic_folder):\n",
    "        # Create the merged_mosaic folder\n",
    "        os.makedirs(cropped_mosaic_folder)\n",
    "\n",
    "\n",
    "    with rs.open(file_path) as dataset:\n",
    "        # Access the data or perform any required operations\n",
    "        data = dataset.read()\n",
    "        # Do something with the data\n",
    "        out_image, out_transform = mask(dataset, reprojected_entry.geometry, crop=True)\n",
    "        out_meta = dataset.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "        output_path = f'cropped_mosaic/{tile}_cropped_mosaic.tif'   \n",
    "        with rs.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "After running the above code we should now have the following folder structure:\n",
    "\n",
    "```\n",
    "notebook\n",
    "├── boreal_agb_density_ICESat2_tiles_shp\n",
    "├── cropped_mosaic\n",
    "├── data\n",
    "├── merged_mosaic\n",
    "├── reprojected_mosaic\n",
    "└── S2_tiles_Siberia_polybox\n",
    "- links.txt\n",
    "- overlapping_tiles.csv\n",
    "- preprocessing.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step we replace the nan values in the cropped mosaics with -9999 and save them into a folder \"cropped_mosaic_no_nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50TPS_cropped_mosaic.tif...\n",
      "Processing 50TPT_cropped_mosaic.tif...\n",
      "Processing 50TQS_cropped_mosaic.tif...\n",
      "Processing 50TQT_cropped_mosaic.tif...\n",
      "Processing 50UQA_cropped_mosaic.tif...\n",
      "Processing 50UQB_cropped_mosaic.tif...\n",
      "Processing 51TVL_cropped_mosaic.tif...\n",
      "Processing 51TVM_cropped_mosaic.tif...\n",
      "Processing 51TVN_cropped_mosaic.tif...\n",
      "Processing 51TWM_cropped_mosaic.tif...\n",
      "Processing 51TWN_cropped_mosaic.tif...\n",
      "Processing 51UUP_cropped_mosaic.tif...\n",
      "Processing 51UUQ_cropped_mosaic.tif...\n",
      "Processing 51UUT_cropped_mosaic.tif...\n",
      "Processing 51UVP_cropped_mosaic.tif...\n",
      "Processing 51UVQ_cropped_mosaic.tif...\n",
      "Processing 51UVR_cropped_mosaic.tif...\n",
      "Processing 51UVS_cropped_mosaic.tif...\n",
      "Processing 51UVT_cropped_mosaic.tif...\n",
      "Processing 51UWP_cropped_mosaic.tif...\n",
      "Processing 51UWQ_cropped_mosaic.tif...\n",
      "Processing 51UWR_cropped_mosaic.tif...\n",
      "Processing 51UWS_cropped_mosaic.tif...\n",
      "Processing 51UWT_cropped_mosaic.tif...\n",
      "Processing 51UXQ_cropped_mosaic.tif...\n",
      "Processing 51UXR_cropped_mosaic.tif...\n",
      "Processing 51UXS_cropped_mosaic.tif...\n",
      "Processing 51UXT_cropped_mosaic.tif...\n",
      "Processing 51UYS_cropped_mosaic.tif...\n",
      "Processing 51UYT_cropped_mosaic.tif...\n",
      "Processing 52UCA_cropped_mosaic.tif...\n",
      "Processing 52UDA_cropped_mosaic.tif...\n",
      "Processing 52UDB_cropped_mosaic.tif...\n",
      "Processing 52UDC_cropped_mosaic.tif...\n",
      "Processing 52UDD_cropped_mosaic.tif...\n",
      "Processing 52UEA_cropped_mosaic.tif...\n",
      "Processing 52UEB_cropped_mosaic.tif...\n",
      "Processing 52UEC_cropped_mosaic.tif...\n",
      "Processing 52UEV_cropped_mosaic.tif...\n",
      "Processing 52UFA_cropped_mosaic.tif...\n",
      "Processing 52UFB_cropped_mosaic.tif...\n",
      "Processing 52UFC_cropped_mosaic.tif...\n",
      "Processing 52UFU_cropped_mosaic.tif...\n",
      "Processing 52UFV_cropped_mosaic.tif...\n",
      "Processing 52UGB_cropped_mosaic.tif...\n",
      "Processing 52UGU_cropped_mosaic.tif...\n",
      "Processing 52VDR_cropped_mosaic.tif...\n",
      "Processing 53TMK_cropped_mosaic.tif...\n",
      "Processing 53TML_cropped_mosaic.tif...\n",
      "Processing 53TMM_cropped_mosaic.tif...\n",
      "Processing 53TNK_cropped_mosaic.tif...\n",
      "Processing 53TNL_cropped_mosaic.tif...\n",
      "Processing 53TNM_cropped_mosaic.tif...\n",
      "Processing 53TNN_cropped_mosaic.tif...\n",
      "Processing 53TPL_cropped_mosaic.tif...\n",
      "Processing 53TPM_cropped_mosaic.tif...\n",
      "Processing 53TPN_cropped_mosaic.tif...\n",
      "Processing 53TQM_cropped_mosaic.tif...\n",
      "Processing 53TQN_cropped_mosaic.tif...\n",
      "Processing 53ULQ_cropped_mosaic.tif...\n",
      "Processing 53ULR_cropped_mosaic.tif...\n",
      "Processing 53ULT_cropped_mosaic.tif...\n",
      "Processing 53UMP_cropped_mosaic.tif...\n",
      "Processing 53UMQ_cropped_mosaic.tif...\n",
      "Processing 53UMR_cropped_mosaic.tif...\n",
      "Processing 53UMS_cropped_mosaic.tif...\n",
      "Processing 53UMT_cropped_mosaic.tif...\n",
      "Processing 53UNP_cropped_mosaic.tif...\n",
      "Processing 53UNQ_cropped_mosaic.tif...\n",
      "Processing 53UNR_cropped_mosaic.tif...\n",
      "Processing 53UNS_cropped_mosaic.tif...\n",
      "Processing 53UNT_cropped_mosaic.tif...\n",
      "Processing 53UPP_cropped_mosaic.tif...\n",
      "Processing 53UPQ_cropped_mosaic.tif...\n",
      "Processing 53UPR_cropped_mosaic.tif...\n",
      "Processing 53UPS_cropped_mosaic.tif...\n",
      "Processing 53UPT_cropped_mosaic.tif...\n",
      "Processing 54UUA_cropped_mosaic.tif...\n",
      "Processing 54UUB_cropped_mosaic.tif...\n",
      "Processing 54UUC_cropped_mosaic.tif...\n",
      "Processing 54UUU_cropped_mosaic.tif...\n",
      "Processing 54UUV_cropped_mosaic.tif...\n",
      "Processing 54UVA_cropped_mosaic.tif...\n",
      "Processing 54UVB_cropped_mosaic.tif...\n",
      "Processing 54UVC_cropped_mosaic.tif...\n",
      "Processing 54UVU_cropped_mosaic.tif...\n",
      "Processing 54UVV_cropped_mosaic.tif...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Define the paths to the input and output folders\n",
    "input_folder = \"cropped_mosaic\"\n",
    "output_folder = \"cropped_mosaic_no_nan\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Get the list of TIFF files in the input folder\n",
    "tif_files = [file for file in os.listdir(input_folder) if file.endswith(\".tif\")]\n",
    "\n",
    "# Iterate over each TIFF file\n",
    "for tif_file in tif_files:\n",
    "    print(f\"Processing {tif_file}...\")\n",
    "    # Read the input TIFF file\n",
    "    input_path = os.path.join(input_folder, tif_file)\n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Read the raster data as a numpy array\n",
    "        data1 = src.read(1)\n",
    "        data2 = src.read(2)\n",
    "        \n",
    "        # Replace NaN values with -9999\n",
    "        data1[np.isnan(data1)] = -9999\n",
    "        data2[np.isnan(data2)] = -9999\n",
    "        \n",
    "        # Create the output TIFF file path\n",
    "        output_path = os.path.join(output_folder, tif_file)\n",
    "        \n",
    "        # Copy the metadata from the input file\n",
    "        profile = src.profile\n",
    "        \n",
    "        # Write the modified data to the output TIFF file\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(data1, 1)\n",
    "            dst.write(data2, 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
